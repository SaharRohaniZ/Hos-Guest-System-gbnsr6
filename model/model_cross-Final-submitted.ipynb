{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Installing RDKit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "k = 4\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adam(0.15)\n",
    "# PGNN: Tanh, Tanh, Tanh, Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/saharctech/Binding-Free-Energy-Prediction-Host-Guest-System/master/Results/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset group name</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Host</th>\n",
       "      <th>Guest</th>\n",
       "      <th>Ex _G_(kcal/mol)</th>\n",
       "      <th>Ex _G_SEM</th>\n",
       "      <th>EX _H_(kcal/mol)</th>\n",
       "      <th>EX _H_SEM</th>\n",
       "      <th>entropy</th>\n",
       "      <th>pb_guest_Etot</th>\n",
       "      <th>...</th>\n",
       "      <th>gb_host_1-4EEL</th>\n",
       "      <th>gb_host_EELEC</th>\n",
       "      <th>gb_host_EGB</th>\n",
       "      <th>gb_host_ESURF</th>\n",
       "      <th>gb_delta_H</th>\n",
       "      <th>pb_delta_H</th>\n",
       "      <th>EX _delta_H_(kcal/mol)</th>\n",
       "      <th>gb_Ex_difference</th>\n",
       "      <th>SQR_gbnsr6_Ex_difference</th>\n",
       "      <th>pb_Ex_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mobley benchmarkset</td>\n",
       "      <td>cd-set1</td>\n",
       "      <td>acd</td>\n",
       "      <td>guest-1</td>\n",
       "      <td>-1.575</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-47.8832</td>\n",
       "      <td>...</td>\n",
       "      <td>423.5761</td>\n",
       "      <td>-428.9520</td>\n",
       "      <td>-96.4471</td>\n",
       "      <td>5.1691</td>\n",
       "      <td>-1.9950</td>\n",
       "      <td>-0.8408</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.030625</td>\n",
       "      <td>1.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mobley benchmarkset</td>\n",
       "      <td>cd-set1</td>\n",
       "      <td>acd</td>\n",
       "      <td>guest-2</td>\n",
       "      <td>-3.533</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-52.0758</td>\n",
       "      <td>...</td>\n",
       "      <td>412.6663</td>\n",
       "      <td>-397.9784</td>\n",
       "      <td>-106.4154</td>\n",
       "      <td>5.0726</td>\n",
       "      <td>-11.2624</td>\n",
       "      <td>-8.4809</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-7.0724</td>\n",
       "      <td>50.018842</td>\n",
       "      <td>-4.2909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mobley benchmarkset</td>\n",
       "      <td>cd-set1</td>\n",
       "      <td>acd</td>\n",
       "      <td>guest-3</td>\n",
       "      <td>-4.606</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-5.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>-51.5323</td>\n",
       "      <td>...</td>\n",
       "      <td>426.2925</td>\n",
       "      <td>-429.3068</td>\n",
       "      <td>-95.2452</td>\n",
       "      <td>5.1352</td>\n",
       "      <td>-15.4074</td>\n",
       "      <td>-13.8234</td>\n",
       "      <td>-5.46</td>\n",
       "      <td>-9.9474</td>\n",
       "      <td>98.950767</td>\n",
       "      <td>-8.3634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mobley benchmarkset</td>\n",
       "      <td>cd-set1</td>\n",
       "      <td>acd</td>\n",
       "      <td>guest-4</td>\n",
       "      <td>-2.130</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>2.3898</td>\n",
       "      <td>...</td>\n",
       "      <td>420.0687</td>\n",
       "      <td>-416.5215</td>\n",
       "      <td>-97.4461</td>\n",
       "      <td>5.0849</td>\n",
       "      <td>-10.5586</td>\n",
       "      <td>-11.3319</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-7.8186</td>\n",
       "      <td>61.130506</td>\n",
       "      <td>-8.5919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobley benchmarkset</td>\n",
       "      <td>cd-set1</td>\n",
       "      <td>acd</td>\n",
       "      <td>guest-5</td>\n",
       "      <td>-2.510</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-3.2280</td>\n",
       "      <td>...</td>\n",
       "      <td>425.7315</td>\n",
       "      <td>-435.9689</td>\n",
       "      <td>-91.2312</td>\n",
       "      <td>5.0881</td>\n",
       "      <td>-14.5517</td>\n",
       "      <td>-14.0485</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-11.5617</td>\n",
       "      <td>133.672907</td>\n",
       "      <td>-11.0585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset group name Dataset Name Host    Guest  Ex _G_(kcal/mol)  \\\n",
       "0  Mobley benchmarkset      cd-set1  acd  guest-1            -1.575   \n",
       "1  Mobley benchmarkset      cd-set1  acd  guest-2            -3.533   \n",
       "2  Mobley benchmarkset      cd-set1  acd  guest-3            -4.606   \n",
       "3  Mobley benchmarkset      cd-set1  acd  guest-4            -2.130   \n",
       "4  Mobley benchmarkset      cd-set1  acd  guest-5            -2.510   \n",
       "\n",
       "   Ex _G_SEM  EX _H_(kcal/mol)  EX _H_SEM  entropy  pb_guest_Etot  ...  \\\n",
       "0      0.019             -2.17       0.05   -0.595       -47.8832  ...   \n",
       "1      0.004             -4.19       0.02   -0.657       -52.0758  ...   \n",
       "2      0.007             -5.46       0.03   -0.854       -51.5323  ...   \n",
       "3      0.016             -2.74       0.02   -0.610         2.3898  ...   \n",
       "4      0.060             -2.99       0.23   -0.480        -3.2280  ...   \n",
       "\n",
       "   gb_host_1-4EEL  gb_host_EELEC  gb_host_EGB  gb_host_ESURF  gb_delta_H  \\\n",
       "0        423.5761      -428.9520     -96.4471         5.1691     -1.9950   \n",
       "1        412.6663      -397.9784    -106.4154         5.0726    -11.2624   \n",
       "2        426.2925      -429.3068     -95.2452         5.1352    -15.4074   \n",
       "3        420.0687      -416.5215     -97.4461         5.0849    -10.5586   \n",
       "4        425.7315      -435.9689     -91.2312         5.0881    -14.5517   \n",
       "\n",
       "   pb_delta_H  EX _delta_H_(kcal/mol)  gb_Ex_difference  \\\n",
       "0     -0.8408                   -2.17            0.1750   \n",
       "1     -8.4809                   -4.19           -7.0724   \n",
       "2    -13.8234                   -5.46           -9.9474   \n",
       "3    -11.3319                   -2.74           -7.8186   \n",
       "4    -14.0485                   -2.99          -11.5617   \n",
       "\n",
       "   SQR_gbnsr6_Ex_difference  pb_Ex_difference  \n",
       "0                  0.030625            1.3292  \n",
       "1                 50.018842           -4.2909  \n",
       "2                 98.950767           -8.3634  \n",
       "3                 61.130506           -8.5919  \n",
       "4                133.672907          -11.0585  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Mobley PDB files</h1>\n",
    "<p>Here each PDB file will be read and saved in Mol data type defined in RDKit and used by DeepChem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with complex names as keys and molecule as values\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '/Users/misspotato/Documents/Github/Binding-Free-Energy-Prediction-Host-Guest-System/PDB_bkp/host-guest'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "for f in onlyfiles:\n",
    "    PDBs.update({f.split('.')[0]: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + '/' + f)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Featurizing</h1>\n",
    "<p>GraphConv model needs ConvMolFeaturizer</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>K-fold cross validation </h4>\n",
    "We have 72 dataponts. We choose k=4 which makes 4 groups of 18 datapoints each.\n",
    "K=4 results 0.25% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_PERCENTAGE = 1-(1/k)\n",
    "VAL_SET_PERCENTAGE = 1/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs.pop('',None)\n",
    "X = []\n",
    "X_ids = []\n",
    "for i in PDBs.keys():\n",
    "    X_ids.append(i)\n",
    "    X.append(featurizer.featurize(PDBs[i]))\n",
    "TEST_SIZE = int(len(X) * VAL_SET_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_names =[]\n",
    "guest_names = []\n",
    "host_names = [i.split('-')[0] for i in X_ids]\n",
    "guest_names = ['guest-' + (i.split('-')[1].replace('s', '')) for i in X_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PGNN model class </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class PGNN(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNN, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 15])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    return self.dense3(binding_affinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data driven class </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# batch_size = int(len(df) / 2)\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "   \n",
    "    def modify_graphgather(self, batch_size):\n",
    "        self.readout.batch_size = batch_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        super(GBGraphConvModel, self).__init__()\n",
    "        self.input_shapes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.gp1 = GraphPool()\n",
    "\n",
    "        self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.gp2 = GraphPool()\n",
    "\n",
    "        self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "        self.batch_norm3 = layers.BatchNormalization()\n",
    "        self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "        self.dense2 = layers.Dense(1, bias_initializer=initializers.Zeros())\n",
    "    #     self.dense3 = layers.Dense(1, \n",
    "    #          kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "    #          bias_initializer=initializers.Zeros())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = inputs[0]\n",
    "        x = []\n",
    "    #     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "    #                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "        for i in range(len(self.input_shapes)):\n",
    "            x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "        for i in range(1, len(self.input_shapes)):\n",
    "            x[i] = tf.cast(x[i], tf.int32)\n",
    "        x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 15])\n",
    "        gc1_output = self.gc1(x)\n",
    "        batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "        gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "        gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "        batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "        gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "        dense1_output = self.dense1(gp2_output)\n",
    "        batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "        readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "\n",
    "        model_var = self.dense2(readout_output)\n",
    "    #     binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "        return model_var #self.dense3(binding_affinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> K-fold cross validation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> pgnn_train_losses: stores the training losses of PGNN model</h5>\n",
    "<h5> pgnn_val_losses: stores the validation losses of PGNN model </h5>\n",
    "<h5> pgnn_rmse_test: stores the PGNN test rmse</h5>\n",
    "<h5> pgnn_rmse_train: stores the PGNN train rmse</h5>\n",
    "<h5> k_fold is the number of folds for cross validation</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_14:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_13:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_17:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_16:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_20:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_19:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_23:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Reshape_22:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_17/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_11:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_10:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_13:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_12:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_15:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_14:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_17:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_16:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_conv_17/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_14:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_13:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_17:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_16:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_20:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_19:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_23:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Reshape_22:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_4/graph_pool_16/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 5s - loss: 96.1594\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 66.7874\n",
      "1/1 - 0s - loss: 83.2979\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 59.5625\n",
      "1/1 - 0s - loss: 70.7791\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 62.8608\n",
      "1/1 - 0s - loss: 62.4801\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 70.8601\n",
      "1/1 - 0s - loss: 61.0256\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 72.7534\n",
      "1/1 - 0s - loss: 59.5907\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 67.7743\n",
      "1/1 - 0s - loss: 55.6003\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 59.6478\n",
      "1/1 - 0s - loss: 50.4079\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 51.6077\n",
      "1/1 - 0s - loss: 45.9494\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 45.6292\n",
      "1/1 - 0s - loss: 42.7601\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 42.3076\n",
      "1/1 - 0s - loss: 40.7511\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.1622\n",
      "1/1 - 0s - loss: 39.5037\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.5985\n",
      "1/1 - 0s - loss: 38.6445\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.2189\n",
      "1/1 - 0s - loss: 37.6719\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 42.8159\n",
      "1/1 - 0s - loss: 36.6317\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 42.9275\n",
      "1/1 - 0s - loss: 35.5452\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 42.3331\n",
      "1/1 - 0s - loss: 34.4626\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 41.3105\n",
      "1/1 - 0s - loss: 33.6348\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.4172\n",
      "1/1 - 0s - loss: 33.3443\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 40.0715\n",
      "1/1 - 0s - loss: 33.4824\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.2401\n",
      "1/1 - 0s - loss: 33.8211\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.6221\n",
      "1/1 - 0s - loss: 33.9558\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.0048\n",
      "1/1 - 0s - loss: 33.8101\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 41.3589\n",
      "1/1 - 0s - loss: 33.5337\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 41.5759\n",
      "1/1 - 0s - loss: 33.3519\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.5201\n",
      "1/1 - 0s - loss: 33.3483\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.0924\n",
      "1/1 - 0s - loss: 33.4934\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 40.4503\n",
      "1/1 - 0s - loss: 33.5910\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.8516\n",
      "1/1 - 0s - loss: 33.5952\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.4184\n",
      "1/1 - 0s - loss: 33.6704\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.2953\n",
      "1/1 - 0s - loss: 33.6132\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.5329\n",
      "1/1 - 0s - loss: 33.4430\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.0947\n",
      "1/1 - 0s - loss: 33.1505\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 40.7306\n",
      "1/1 - 0s - loss: 33.0213\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 41.2846\n",
      "1/1 - 0s - loss: 32.9790\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 41.4792\n",
      "1/1 - 0s - loss: 32.8790\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 41.2190\n",
      "1/1 - 0s - loss: 32.7428\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 40.6068\n",
      "1/1 - 0s - loss: 32.5790\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 39.9074\n",
      "1/1 - 0s - loss: 32.4140\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.3330\n",
      "1/1 - 0s - loss: 32.2660\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.9688\n",
      "1/1 - 0s - loss: 32.1320\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.9020\n",
      "1/1 - 0s - loss: 32.0013\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 39.0299\n",
      "1/1 - 0s - loss: 31.9015\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.1543\n",
      "1/1 - 0s - loss: 31.7703\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.1524\n",
      "1/1 - 0s - loss: 31.6793\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.0570\n",
      "1/1 - 0s - loss: 31.6434\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.9560\n",
      "1/1 - 0s - loss: 31.5778\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.8513\n",
      "1/1 - 0s - loss: 31.5061\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.8048\n",
      "1/1 - 0s - loss: 31.4132\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.8156\n",
      "1/1 - 0s - loss: 31.3537\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.7715\n",
      "1/1 - 0s - loss: 31.3268\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.6467\n",
      "1/1 - 0s - loss: 31.2611\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.5011\n",
      "1/1 - 0s - loss: 31.1796\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.3649\n",
      "1/1 - 0s - loss: 31.1617\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.2644\n",
      "1/1 - 0s - loss: 31.0901\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.1498\n",
      "1/1 - 0s - loss: 31.0429\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.0562\n",
      "1/1 - 0s - loss: 31.0025\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 37.9544\n",
      "1/1 - 0s - loss: 30.9297\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 37.9175\n",
      "1/1 - 0s - loss: 30.8774\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.9692\n",
      "1/1 - 0s - loss: 30.7985\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.0457\n",
      "1/1 - 0s - loss: 30.7908\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.0331\n",
      "1/1 - 0s - loss: 30.6932\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.0151\n",
      "1/1 - 0s - loss: 30.6464\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 38.0242\n",
      "1/1 - 0s - loss: 30.5779\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.0306\n",
      "1/1 - 0s - loss: 30.5273\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.9328\n",
      "1/1 - 0s - loss: 30.4392\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.7906\n",
      "1/1 - 0s - loss: 30.3971\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.7065\n",
      "1/1 - 0s - loss: 30.3277\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.6261\n",
      "1/1 - 0s - loss: 30.2870\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.5437\n",
      "1/1 - 0s - loss: 30.2195\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.5459\n",
      "1/1 - 0s - loss: 30.1695\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 37.6689\n",
      "1/1 - 0s - loss: 30.1010\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.8490\n",
      "1/1 - 0s - loss: 30.0249\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.1499\n",
      "1/1 - 0s - loss: 29.9807\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.4260\n",
      "1/1 - 0s - loss: 29.8932\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.4987\n",
      "1/1 - 0s - loss: 29.8550\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.3356\n",
      "1/1 - 0s - loss: 29.8704\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.0345\n",
      "1/1 - 0s - loss: 29.7892\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.6159\n",
      "1/1 - 0s - loss: 29.8223\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 37.1256\n",
      "1/1 - 0s - loss: 29.7973\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.8362\n",
      "1/1 - 0s - loss: 29.7557\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.7234\n",
      "1/1 - 0s - loss: 29.6932\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.7542\n",
      "1/1 - 0s - loss: 29.6460\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.8950\n",
      "1/1 - 0s - loss: 29.5753\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 36.9520\n",
      "1/1 - 0s - loss: 29.4955\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 36.8433\n",
      "1/1 - 0s - loss: 29.4927\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.7012\n",
      "1/1 - 0s - loss: 29.4187\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 36.5289\n",
      "1/1 - 0s - loss: 29.3372\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.4097\n",
      "1/1 - 0s - loss: 29.3269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 36.4169\n",
      "1/1 - 0s - loss: 29.2567\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.3753\n",
      "1/1 - 0s - loss: 29.1618\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 36.2653\n",
      "1/1 - 0s - loss: 29.1409\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.1295\n",
      "1/1 - 0s - loss: 29.0880\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.8930\n",
      "1/1 - 0s - loss: 29.0008\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 35.6941\n",
      "1/1 - 0s - loss: 28.9832\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 35.6450\n",
      "1/1 - 0s - loss: 28.9332\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.6287\n",
      "1/1 - 0s - loss: 28.8125\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 35.6627\n",
      "1/1 - 0s - loss: 28.7925\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.6715\n",
      "1/1 - 0s - loss: 28.7316\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.7102\n",
      "1/1 - 0s - loss: 28.5929\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.6628\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.6628\n",
      "[5.9718297233042925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_14:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_13:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_17:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_16:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_20:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_19:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_23:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Reshape_22:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_11:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_10:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_13:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_12:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_15:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_14:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_17:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_16:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_conv_19/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_14:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_13:0\", shape=(1134, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_17:0\", shape=(3714,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_16:0\", shape=(3714, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_20:0\", shape=(7182,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_19:0\", shape=(7182, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_23:0\", shape=(24,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Reshape_22:0\", shape=(24, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_4/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 5s - loss: 27.4926\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 33.0349\n",
      "1/1 - 0s - loss: 24.2319\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.1508\n",
      "1/1 - 0s - loss: 22.3884\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.7901\n",
      "1/1 - 0s - loss: 20.5415\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.6047\n",
      "1/1 - 0s - loss: 19.3050\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.9066\n",
      "1/1 - 0s - loss: 18.2162\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.8618\n",
      "1/1 - 0s - loss: 17.5958\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 33.5356\n",
      "1/1 - 0s - loss: 16.7715\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 33.0839\n",
      "1/1 - 0s - loss: 16.3110\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 33.1157\n",
      "1/1 - 0s - loss: 15.9378\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 33.5666\n",
      "1/1 - 0s - loss: 15.5392\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 33.4491\n",
      "1/1 - 0s - loss: 15.3288\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 32.8551\n",
      "1/1 - 0s - loss: 14.9685\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 32.1268\n",
      "1/1 - 0s - loss: 14.6342\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 31.0746\n",
      "1/1 - 0s - loss: 14.4085\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 30.0336\n",
      "1/1 - 0s - loss: 14.1232\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 29.3205\n",
      "1/1 - 0s - loss: 13.9621\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.8768\n",
      "1/1 - 0s - loss: 13.7524\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.6350\n",
      "1/1 - 0s - loss: 13.4923\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.3164\n",
      "1/1 - 0s - loss: 13.3213\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.8400\n",
      "1/1 - 0s - loss: 13.2003\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.4232\n",
      "1/1 - 0s - loss: 13.0855\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.0539\n",
      "1/1 - 0s - loss: 12.9560\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.7652\n",
      "1/1 - 0s - loss: 12.8310\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.6174\n",
      "1/1 - 0s - loss: 12.7413\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.4669\n",
      "1/1 - 0s - loss: 12.6598\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.2330\n",
      "1/1 - 0s - loss: 12.5814\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.0389\n",
      "1/1 - 0s - loss: 12.5041\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.7777\n",
      "1/1 - 0s - loss: 12.4310\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 25.3967\n",
      "1/1 - 0s - loss: 12.3593\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.9167\n",
      "1/1 - 0s - loss: 12.2922\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.4018\n",
      "1/1 - 0s - loss: 12.2380\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.8934\n",
      "1/1 - 0s - loss: 12.1922\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.4169\n",
      "1/1 - 0s - loss: 12.1571\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.0386\n",
      "1/1 - 0s - loss: 12.1261\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.7563\n",
      "1/1 - 0s - loss: 12.0974\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.5297\n",
      "1/1 - 0s - loss: 12.0701\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 22.3232\n",
      "1/1 - 0s - loss: 12.0458\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 22.0865\n",
      "1/1 - 0s - loss: 12.0273\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 21.8648\n",
      "1/1 - 0s - loss: 12.0125\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.6739\n",
      "1/1 - 0s - loss: 11.9995\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.4629\n",
      "1/1 - 0s - loss: 11.9881\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 21.2471\n",
      "1/1 - 0s - loss: 11.9781\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 21.0341\n",
      "1/1 - 0s - loss: 11.9693\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.8089\n",
      "1/1 - 0s - loss: 11.9616\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.5713\n",
      "1/1 - 0s - loss: 11.9551\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.3362\n",
      "1/1 - 0s - loss: 11.9499\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.1419\n",
      "1/1 - 0s - loss: 11.9457\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.9921\n",
      "1/1 - 0s - loss: 11.9422\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.8764\n",
      "1/1 - 0s - loss: 11.9392\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.8072\n",
      "1/1 - 0s - loss: 11.9363\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.7507\n",
      "1/1 - 0s - loss: 11.9336\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.6730\n",
      "1/1 - 0s - loss: 11.9311\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.6679\n",
      "1/1 - 0s - loss: 11.9290\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.6949\n",
      "1/1 - 0s - loss: 11.9273\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.6805\n",
      "1/1 - 0s - loss: 11.9258\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.6768\n",
      "1/1 - 0s - loss: 11.9243\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.6487\n",
      "1/1 - 0s - loss: 11.9224\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.5624\n",
      "1/1 - 0s - loss: 11.9202\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.4496\n",
      "1/1 - 0s - loss: 11.9180\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.3389\n",
      "1/1 - 0s - loss: 11.9160\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.2456\n",
      "1/1 - 0s - loss: 11.9140\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.1512\n",
      "1/1 - 0s - loss: 11.9122\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.0878\n",
      "1/1 - 0s - loss: 11.9106\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.0540\n",
      "1/1 - 0s - loss: 11.9089\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.0055\n",
      "1/1 - 0s - loss: 11.9071\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 18.9716\n",
      "1/1 - 0s - loss: 11.9052\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.9495\n",
      "1/1 - 0s - loss: 11.9035\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.9055\n",
      "1/1 - 0s - loss: 11.9020\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8046\n",
      "1/1 - 0s - loss: 11.9006\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.6538\n",
      "1/1 - 0s - loss: 11.8992\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.5202\n",
      "1/1 - 0s - loss: 11.8979\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.3835\n",
      "1/1 - 0s - loss: 11.8967\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.2247\n",
      "1/1 - 0s - loss: 11.8955\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.0921\n",
      "1/1 - 0s - loss: 11.8945\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.0010\n",
      "1/1 - 0s - loss: 11.8936\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.9393\n",
      "1/1 - 0s - loss: 11.8926\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.8965\n",
      "1/1 - 0s - loss: 11.8916\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.8688\n",
      "1/1 - 0s - loss: 11.8908\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8617\n",
      "1/1 - 0s - loss: 11.8899\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.8769\n",
      "1/1 - 0s - loss: 11.8891\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.9240\n",
      "1/1 - 0s - loss: 11.8885\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.9987\n",
      "1/1 - 0s - loss: 11.8879\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.0661\n",
      "1/1 - 0s - loss: 11.8872\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.1017\n",
      "1/1 - 0s - loss: 11.8865\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.0969\n",
      "1/1 - 0s - loss: 11.8859\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.0729\n",
      "1/1 - 0s - loss: 11.8853\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.0585\n",
      "1/1 - 0s - loss: 11.8848\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.0420\n",
      "1/1 - 0s - loss: 11.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 17.9953\n",
      "1/1 - 0s - loss: 11.8835\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.9205\n",
      "1/1 - 0s - loss: 11.8830\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.8356\n",
      "1/1 - 0s - loss: 11.8825\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.7511\n",
      "1/1 - 0s - loss: 11.8819\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.6655\n",
      "1/1 - 0s - loss: 11.8813\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.5745\n",
      "1/1 - 0s - loss: 11.8805\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.4751\n",
      "1/1 - 0s - loss: 11.8796\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.3648\n",
      "1/1 - 0s - loss: 11.8790\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.2483\n",
      "1/1 - 0s - loss: 11.8785\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.1331\n",
      "1/1 - 0s - loss: 11.8781\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.0243\n",
      "1/1 - 0s - loss: 11.8778\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.9270\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.9270\n",
      "[4.114242861539711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_14:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_13:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_17:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_16:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_20:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_19:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_23:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Reshape_22:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_21/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_11:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_10:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_13:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_12:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_15:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_14:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_17:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_16:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_conv_21/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_14:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_13:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_17:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_16:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_20:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_19:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_23:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Reshape_22:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_5/graph_pool_20/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 5s - loss: 100.6149\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 72.6432\n",
      "1/1 - 0s - loss: 73.5725\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 77.7889\n",
      "1/1 - 0s - loss: 69.3365\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 77.3020\n",
      "1/1 - 0s - loss: 63.9986\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 74.7936\n",
      "1/1 - 0s - loss: 59.9407\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 73.5480\n",
      "1/1 - 0s - loss: 58.6211\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 71.9920\n",
      "1/1 - 0s - loss: 58.1603\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 67.5505\n",
      "1/1 - 0s - loss: 55.5791\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 61.5104\n",
      "1/1 - 0s - loss: 51.7427\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 55.3625\n",
      "1/1 - 0s - loss: 47.2387\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 50.8050\n",
      "1/1 - 0s - loss: 43.6104\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 48.2450\n",
      "1/1 - 0s - loss: 42.6055\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.9586\n",
      "1/1 - 0s - loss: 42.7517\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 45.4179\n",
      "1/1 - 0s - loss: 43.0763\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 42.8654\n",
      "1/1 - 0s - loss: 42.4739\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 39.4256\n",
      "1/1 - 0s - loss: 41.1995\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 36.0220\n",
      "1/1 - 0s - loss: 40.3172\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 33.5241\n",
      "1/1 - 0s - loss: 39.6394\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 31.9671\n",
      "1/1 - 0s - loss: 39.1815\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.2298\n",
      "1/1 - 0s - loss: 38.5679\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.1709\n",
      "1/1 - 0s - loss: 38.0531\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 31.6474\n",
      "1/1 - 0s - loss: 37.8241\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 32.3800\n",
      "1/1 - 0s - loss: 37.8734\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 32.8961\n",
      "1/1 - 0s - loss: 38.1465\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 32.6550\n",
      "1/1 - 0s - loss: 38.1362\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.5267\n",
      "1/1 - 0s - loss: 37.7772\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 29.9145\n",
      "1/1 - 0s - loss: 37.2976\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.3024\n",
      "1/1 - 0s - loss: 36.8854\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.0595\n",
      "1/1 - 0s - loss: 36.7333\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.3271\n",
      "1/1 - 0s - loss: 36.7155\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 26.0618\n",
      "1/1 - 0s - loss: 36.7175\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 26.1797\n",
      "1/1 - 0s - loss: 36.5032\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 26.5906\n",
      "1/1 - 0s - loss: 36.2469\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.1872\n",
      "1/1 - 0s - loss: 35.9943\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.7066\n",
      "1/1 - 0s - loss: 35.8690\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.0651\n",
      "1/1 - 0s - loss: 35.5705\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 28.1503\n",
      "1/1 - 0s - loss: 35.2655\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0341\n",
      "1/1 - 0s - loss: 35.0200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.9110\n",
      "1/1 - 0s - loss: 34.8259\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.8902\n",
      "1/1 - 0s - loss: 34.6674\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.9641\n",
      "1/1 - 0s - loss: 34.5636\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.1223\n",
      "1/1 - 0s - loss: 34.3925\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.4158\n",
      "1/1 - 0s - loss: 34.1512\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.9130\n",
      "1/1 - 0s - loss: 33.9734\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 29.3601\n",
      "1/1 - 0s - loss: 33.7958\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.4586\n",
      "1/1 - 0s - loss: 33.6332\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.2302\n",
      "1/1 - 0s - loss: 33.5147\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.8527\n",
      "1/1 - 0s - loss: 33.3584\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.4960\n",
      "1/1 - 0s - loss: 33.2646\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.1850\n",
      "1/1 - 0s - loss: 33.1707\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.9970\n",
      "1/1 - 0s - loss: 33.0659\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.1160\n",
      "1/1 - 0s - loss: 32.9153\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.3879\n",
      "1/1 - 0s - loss: 32.7663\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.7504\n",
      "1/1 - 0s - loss: 32.6415\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.1054\n",
      "1/1 - 0s - loss: 32.5367\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.2925\n",
      "1/1 - 0s - loss: 32.4726\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.2473\n",
      "1/1 - 0s - loss: 32.3136\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.0228\n",
      "1/1 - 0s - loss: 32.1993\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.7327\n",
      "1/1 - 0s - loss: 32.1032\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.4576\n",
      "1/1 - 0s - loss: 31.9753\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.3691\n",
      "1/1 - 0s - loss: 31.9067\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.4657\n",
      "1/1 - 0s - loss: 31.8133\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.5796\n",
      "1/1 - 0s - loss: 31.6927\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.6966\n",
      "1/1 - 0s - loss: 31.5910\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.7335\n",
      "1/1 - 0s - loss: 31.5051\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.6255\n",
      "1/1 - 0s - loss: 31.3986\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4047\n",
      "1/1 - 0s - loss: 31.3008\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.1228\n",
      "1/1 - 0s - loss: 31.1920\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.8859\n",
      "1/1 - 0s - loss: 31.0942\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.7366\n",
      "1/1 - 0s - loss: 31.0022\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.6784\n",
      "1/1 - 0s - loss: 30.8991\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.7109\n",
      "1/1 - 0s - loss: 30.7843\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8049\n",
      "1/1 - 0s - loss: 30.6962\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.9232\n",
      "1/1 - 0s - loss: 30.6557\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.9018\n",
      "1/1 - 0s - loss: 30.5122\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.8176\n",
      "1/1 - 0s - loss: 30.4233\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.8215\n",
      "1/1 - 0s - loss: 30.2737\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.7962\n",
      "1/1 - 0s - loss: 30.2529\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.7304\n",
      "1/1 - 0s - loss: 30.1768\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.6836\n",
      "1/1 - 0s - loss: 30.0365\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.7150\n",
      "1/1 - 0s - loss: 29.9396\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.8584\n",
      "1/1 - 0s - loss: 29.8828\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.9668\n",
      "1/1 - 0s - loss: 29.7829\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.0377\n",
      "1/1 - 0s - loss: 29.6545\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.0031\n",
      "1/1 - 0s - loss: 29.6769\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.8324\n",
      "1/1 - 0s - loss: 29.6958\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.7670\n",
      "1/1 - 0s - loss: 29.5888\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.7343\n",
      "1/1 - 0s - loss: 29.3843\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.6680\n",
      "1/1 - 0s - loss: 29.3472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 27.5879\n",
      "1/1 - 0s - loss: 29.3564\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.5832\n",
      "1/1 - 0s - loss: 29.2569\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.4010\n",
      "1/1 - 0s - loss: 29.2743\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.1999\n",
      "1/1 - 0s - loss: 29.1082\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.1064\n",
      "1/1 - 0s - loss: 29.0494\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.3531\n",
      "1/1 - 0s - loss: 28.9385\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.5930\n",
      "1/1 - 0s - loss: 29.2445\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.6827\n",
      "1/1 - 0s - loss: 28.7259\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.6384\n",
      "1/1 - 0s - loss: 29.1076\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.8459\n",
      "1/1 - 0s - loss: 29.1611\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0004\n",
      "1/1 - 0s - loss: 28.9544\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.1611\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.1611\n",
      "[5.9718297233042925, 5.306703883732268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_14:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_13:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_17:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_16:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_20:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_19:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_23:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Reshape_22:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_11:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_10:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_13:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_12:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_15:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_14:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_17:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_16:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_23/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_14:0\", shape=(1133,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_13:0\", shape=(1133, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_17:0\", shape=(3728,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_16:0\", shape=(3728, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_20:0\", shape=(7263,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_19:0\", shape=(7263, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_23:0\", shape=(36,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Reshape_22:0\", shape=(36, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 4s - loss: 43.1007\n",
      "1/1 [==============================] - 1s 1s/step - loss: 28.1062\n",
      "1/1 - 0s - loss: 36.7387\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.8815\n",
      "1/1 - 0s - loss: 33.1949\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.9785\n",
      "1/1 - 0s - loss: 29.9733\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.7420\n",
      "1/1 - 0s - loss: 28.2189\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 27.5673\n",
      "1/1 - 0s - loss: 25.9041\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.9477\n",
      "1/1 - 0s - loss: 22.7138\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.7836\n",
      "1/1 - 0s - loss: 20.9928\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.9565\n",
      "1/1 - 0s - loss: 19.6860\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.7423\n",
      "1/1 - 0s - loss: 19.3072\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.5099\n",
      "1/1 - 0s - loss: 18.8131\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0387\n",
      "1/1 - 0s - loss: 18.4991\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.7321\n",
      "1/1 - 0s - loss: 18.1407\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.4628\n",
      "1/1 - 0s - loss: 17.5557\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.2448\n",
      "1/1 - 0s - loss: 17.1132\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.3079\n",
      "1/1 - 0s - loss: 16.5960\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.4642\n",
      "1/1 - 0s - loss: 16.1156\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.4131\n",
      "1/1 - 0s - loss: 15.4945\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.3637\n",
      "1/1 - 0s - loss: 15.0470\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.3559\n",
      "1/1 - 0s - loss: 14.8560\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 27.1756\n",
      "1/1 - 0s - loss: 14.7320\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 26.7876\n",
      "1/1 - 0s - loss: 14.5618\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 26.5974\n",
      "1/1 - 0s - loss: 14.3944\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 26.2010\n",
      "1/1 - 0s - loss: 14.2679\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25.8137\n",
      "1/1 - 0s - loss: 14.1318\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25.4394\n",
      "1/1 - 0s - loss: 13.9779\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25.0116\n",
      "1/1 - 0s - loss: 13.8511\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 24.6987\n",
      "1/1 - 0s - loss: 13.7373\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 24.2950\n",
      "1/1 - 0s - loss: 13.6753\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 24.0212\n",
      "1/1 - 0s - loss: 13.6213\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.7723\n",
      "1/1 - 0s - loss: 13.5745\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 23.4548\n",
      "1/1 - 0s - loss: 13.5266\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 23.0747\n",
      "1/1 - 0s - loss: 13.4855\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 22.6934\n",
      "1/1 - 0s - loss: 13.4517\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 22.3459\n",
      "1/1 - 0s - loss: 13.4244\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 22.0246\n",
      "1/1 - 0s - loss: 13.4016\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 21.6923\n",
      "1/1 - 0s - loss: 13.3811\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 21.3445\n",
      "1/1 - 0s - loss: 13.3629\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 21.0503\n",
      "1/1 - 0s - loss: 13.3464\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 20.8526\n",
      "1/1 - 0s - loss: 13.3308\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.7224\n",
      "1/1 - 0s - loss: 13.3159\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 20.5861\n",
      "1/1 - 0s - loss: 13.3014\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 20.4632\n",
      "1/1 - 0s - loss: 13.2864\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.3743\n",
      "1/1 - 0s - loss: 13.2715\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.3294\n",
      "1/1 - 0s - loss: 13.2577\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.2852\n",
      "1/1 - 0s - loss: 13.2437\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.2056\n",
      "1/1 - 0s - loss: 13.2294\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.0747\n",
      "1/1 - 0s - loss: 13.2148\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.9358\n",
      "1/1 - 0s - loss: 13.1988\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 19.8988\n",
      "1/1 - 0s - loss: 13.1789\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.7604\n",
      "1/1 - 0s - loss: 13.1540\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.5942\n",
      "1/1 - 0s - loss: 13.1344\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4564\n",
      "1/1 - 0s - loss: 13.1174\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4249\n",
      "1/1 - 0s - loss: 13.1056\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4569\n",
      "1/1 - 0s - loss: 13.0941\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4534\n",
      "1/1 - 0s - loss: 13.0829\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4811\n",
      "1/1 - 0s - loss: 13.0721\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.4617\n",
      "1/1 - 0s - loss: 13.0619\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.3842\n",
      "1/1 - 0s - loss: 13.0524\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.2988\n",
      "1/1 - 0s - loss: 13.0437\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.2182\n",
      "1/1 - 0s - loss: 13.0358\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.1367\n",
      "1/1 - 0s - loss: 13.0283\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.0440\n",
      "1/1 - 0s - loss: 13.0216\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 18.9365\n",
      "1/1 - 0s - loss: 13.0158\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.8268\n",
      "1/1 - 0s - loss: 13.0103\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.7267\n",
      "1/1 - 0s - loss: 13.0052\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.6391\n",
      "1/1 - 0s - loss: 13.0002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.5569\n",
      "1/1 - 0s - loss: 12.9955\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.4734\n",
      "1/1 - 0s - loss: 12.9909\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.3878\n",
      "1/1 - 0s - loss: 12.9865\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.3021\n",
      "1/1 - 0s - loss: 12.9822\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.2200\n",
      "1/1 - 0s - loss: 12.9781\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.1512\n",
      "1/1 - 0s - loss: 12.9742\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.0922\n",
      "1/1 - 0s - loss: 12.9706\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 18.0133\n",
      "1/1 - 0s - loss: 12.9672\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.9206\n",
      "1/1 - 0s - loss: 12.9641\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.8559\n",
      "1/1 - 0s - loss: 12.9611\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.8115\n",
      "1/1 - 0s - loss: 12.9582\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.7680\n",
      "1/1 - 0s - loss: 12.9554\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.7225\n",
      "1/1 - 0s - loss: 12.9528\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.6764\n",
      "1/1 - 0s - loss: 12.9503\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.6693\n",
      "1/1 - 0s - loss: 12.9480\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.6792\n",
      "1/1 - 0s - loss: 12.9459\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.6984\n",
      "1/1 - 0s - loss: 12.9439\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.7485\n",
      "1/1 - 0s - loss: 12.9420\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.8094\n",
      "1/1 - 0s - loss: 12.9402\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8289\n",
      "1/1 - 0s - loss: 12.9385\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.8375\n",
      "1/1 - 0s - loss: 12.9369\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.8707\n",
      "1/1 - 0s - loss: 12.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 17.9380\n",
      "1/1 - 0s - loss: 12.9341\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 17.9845\n",
      "1/1 - 0s - loss: 12.9328\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.9978\n",
      "1/1 - 0s - loss: 12.9315\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 18.0083\n",
      "1/1 - 0s - loss: 12.9303\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.9832\n",
      "1/1 - 0s - loss: 12.9292\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 17.9264\n",
      "1/1 - 0s - loss: 12.9281\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 17.8556\n",
      "1/1 - 0s - loss: 12.9271\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.7754\n",
      "1/1 - 0s - loss: 12.9261\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.6891\n",
      "1/1 - 0s - loss: 12.9252\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.6075\n",
      "1/1 - 0s - loss: 12.9243\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.5409\n",
      "1/1 - 0s - loss: 12.9235\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 17.4892\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.4892\n",
      "[4.114242861539711, 4.182009613420117]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_14:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_13:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_17:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_16:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_20:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_19:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_23:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Reshape_22:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_25/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_11:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_10:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_13:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_12:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_15:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_14:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_17:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_16:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_conv_25/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_14:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_13:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_17:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_16:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_20:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_19:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_23:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Reshape_22:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_6/graph_pool_24/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 4s - loss: 85.6264\n",
      "1/1 [==============================] - 1s 1s/step - loss: 62.5661\n",
      "1/1 - 0s - loss: 66.7776\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 48.8370\n",
      "1/1 - 0s - loss: 63.1362\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 43.6014\n",
      "1/1 - 0s - loss: 57.3143\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 44.0428\n",
      "1/1 - 0s - loss: 53.2088\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.4135\n",
      "1/1 - 0s - loss: 51.7321\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 48.9814\n",
      "1/1 - 0s - loss: 50.0243\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 47.0765\n",
      "1/1 - 0s - loss: 46.3238\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 42.9967\n",
      "1/1 - 0s - loss: 42.4020\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 39.2558\n",
      "1/1 - 0s - loss: 39.2924\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 36.9994\n",
      "1/1 - 0s - loss: 37.6228\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 36.4529\n",
      "1/1 - 0s - loss: 37.3269\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 36.6004\n",
      "1/1 - 0s - loss: 36.7922\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 36.6913\n",
      "1/1 - 0s - loss: 35.6869\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 36.5145\n",
      "1/1 - 0s - loss: 34.2291\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 36.1374\n",
      "1/1 - 0s - loss: 33.2716\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 35.3386\n",
      "1/1 - 0s - loss: 32.7830\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 33.7858\n",
      "1/1 - 0s - loss: 32.5577\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 31.5356\n",
      "1/1 - 0s - loss: 32.3584\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.0520\n",
      "1/1 - 0s - loss: 32.1934\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 26.8476\n",
      "1/1 - 0s - loss: 32.1704\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 25.3873\n",
      "1/1 - 0s - loss: 32.2045\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.9039\n",
      "1/1 - 0s - loss: 31.9750\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.3935\n",
      "1/1 - 0s - loss: 31.8338\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 26.9973\n",
      "1/1 - 0s - loss: 31.5542\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.2301\n",
      "1/1 - 0s - loss: 31.2673\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 31.4218\n",
      "1/1 - 0s - loss: 31.1909\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 32.9063\n",
      "1/1 - 0s - loss: 31.2763\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 33.1414\n",
      "1/1 - 0s - loss: 31.1684\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 32.2489\n",
      "1/1 - 0s - loss: 30.7240\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 30.8079\n",
      "1/1 - 0s - loss: 30.4033\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.4096\n",
      "1/1 - 0s - loss: 30.1429\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.4008\n",
      "1/1 - 0s - loss: 29.9720\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 27.9960\n",
      "1/1 - 0s - loss: 29.7974\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.1684\n",
      "1/1 - 0s - loss: 29.4652\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.8121\n",
      "1/1 - 0s - loss: 29.3577\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 29.5335\n",
      "1/1 - 0s - loss: 29.3012\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.8659\n",
      "1/1 - 0s - loss: 29.1333\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.7379\n",
      "1/1 - 0s - loss: 28.8279\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.4121\n",
      "1/1 - 0s - loss: 28.5375\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.2033\n",
      "1/1 - 0s - loss: 28.3473\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.3794\n",
      "1/1 - 0s - loss: 28.3250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 30.0102\n",
      "1/1 - 0s - loss: 28.1411\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.7854\n",
      "1/1 - 0s - loss: 27.8861\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 31.5190\n",
      "1/1 - 0s - loss: 27.8112\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.8846\n",
      "1/1 - 0s - loss: 27.7841\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 31.6909\n",
      "1/1 - 0s - loss: 27.6525\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 30.9953\n",
      "1/1 - 0s - loss: 27.4451\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 30.0466\n",
      "1/1 - 0s - loss: 27.3337\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.2886\n",
      "1/1 - 0s - loss: 27.2730\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.9447\n",
      "1/1 - 0s - loss: 27.1955\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.9388\n",
      "1/1 - 0s - loss: 27.0708\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.2898\n",
      "1/1 - 0s - loss: 26.9297\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.8205\n",
      "1/1 - 0s - loss: 26.8430\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.2296\n",
      "1/1 - 0s - loss: 26.7952\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 30.3703\n",
      "1/1 - 0s - loss: 26.7120\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 30.2184\n",
      "1/1 - 0s - loss: 26.6233\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.8856\n",
      "1/1 - 0s - loss: 26.5325\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.5522\n",
      "1/1 - 0s - loss: 26.4500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.3474\n",
      "1/1 - 0s - loss: 26.3494\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.3009\n",
      "1/1 - 0s - loss: 26.2321\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.3357\n",
      "1/1 - 0s - loss: 26.1518\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.3202\n",
      "1/1 - 0s - loss: 26.0912\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.1655\n",
      "1/1 - 0s - loss: 26.0031\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.0003\n",
      "1/1 - 0s - loss: 25.9150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.8671\n",
      "1/1 - 0s - loss: 25.8325\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.7974\n",
      "1/1 - 0s - loss: 25.7208\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.8766\n",
      "1/1 - 0s - loss: 25.5761\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.0008\n",
      "1/1 - 0s - loss: 25.4665\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.1273\n",
      "1/1 - 0s - loss: 25.3799\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 29.1755\n",
      "1/1 - 0s - loss: 25.3018\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 29.0976\n",
      "1/1 - 0s - loss: 25.2277\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.8888\n",
      "1/1 - 0s - loss: 25.1305\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.6600\n",
      "1/1 - 0s - loss: 25.0294\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4981\n",
      "1/1 - 0s - loss: 24.9528\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.4805\n",
      "1/1 - 0s - loss: 24.8856\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.5820\n",
      "1/1 - 0s - loss: 24.8025\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.7417\n",
      "1/1 - 0s - loss: 24.7013\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.8955\n",
      "1/1 - 0s - loss: 24.6156\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.9807\n",
      "1/1 - 0s - loss: 24.5585\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.9503\n",
      "1/1 - 0s - loss: 24.4917\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.7925\n",
      "1/1 - 0s - loss: 24.4134\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.6927\n",
      "1/1 - 0s - loss: 24.3344\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.6234\n",
      "1/1 - 0s - loss: 24.2531\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.5948\n",
      "1/1 - 0s - loss: 24.1743\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.6135\n",
      "1/1 - 0s - loss: 24.0217\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.5713\n",
      "1/1 - 0s - loss: 23.9680\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.4850\n",
      "1/1 - 0s - loss: 23.8742\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.3949\n",
      "1/1 - 0s - loss: 23.8083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 28.3296\n",
      "1/1 - 0s - loss: 23.7460\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.3028\n",
      "1/1 - 0s - loss: 23.6851\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.3159\n",
      "1/1 - 0s - loss: 23.6240\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.3601\n",
      "1/1 - 0s - loss: 23.5591\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.3869\n",
      "1/1 - 0s - loss: 23.4860\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.3591\n",
      "1/1 - 0s - loss: 23.4184\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.2948\n",
      "1/1 - 0s - loss: 23.3505\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.2197\n",
      "1/1 - 0s - loss: 23.2894\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.1020\n",
      "1/1 - 0s - loss: 23.2113\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0450\n",
      "1/1 - 0s - loss: 23.1650\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0611\n",
      "1/1 - 0s - loss: 23.0995\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.0971\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 28.0971\n",
      "[5.9718297233042925, 5.306703883732268, 5.300665385386257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_14:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_13:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_17:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_16:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_20:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_19:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_23:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Reshape_22:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_11:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_10:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_13:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_12:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_15:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_14:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_17:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_16:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_conv_27/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_14:0\", shape=(1147,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_13:0\", shape=(1147, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_17:0\", shape=(3600,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_16:0\", shape=(3600, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_20:0\", shape=(7191,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_19:0\", shape=(7191, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_23:0\", shape=(28,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Reshape_22:0\", shape=(28, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_6/graph_pool_26/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 4s - loss: 29.1366\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 70.3856\n",
      "1/1 - 0s - loss: 23.3372\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 68.2169\n",
      "1/1 - 0s - loss: 21.4958\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 66.2593\n",
      "1/1 - 0s - loss: 19.7950\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 65.4487\n",
      "1/1 - 0s - loss: 19.0372\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.5469\n",
      "1/1 - 0s - loss: 18.3220\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.6856\n",
      "1/1 - 0s - loss: 17.2577\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.1860\n",
      "1/1 - 0s - loss: 16.1528\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.5644\n",
      "1/1 - 0s - loss: 15.3178\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 62.9208\n",
      "1/1 - 0s - loss: 14.8739\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 62.7718\n",
      "1/1 - 0s - loss: 14.4711\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.5539\n",
      "1/1 - 0s - loss: 14.1276\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.3519\n",
      "1/1 - 0s - loss: 13.7096\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 65.1024\n",
      "1/1 - 0s - loss: 13.3947\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.9895\n",
      "1/1 - 0s - loss: 13.1411\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.5408\n",
      "1/1 - 0s - loss: 12.8877\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.4559\n",
      "1/1 - 0s - loss: 12.6032\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.5372\n",
      "1/1 - 0s - loss: 12.3198\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.3589\n",
      "1/1 - 0s - loss: 12.1299\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.8209\n",
      "1/1 - 0s - loss: 11.9730\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.3679\n",
      "1/1 - 0s - loss: 11.8274\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 63.5159\n",
      "1/1 - 0s - loss: 11.7277\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.1027\n",
      "1/1 - 0s - loss: 11.6213\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.5951\n",
      "1/1 - 0s - loss: 11.5204\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.1412\n",
      "1/1 - 0s - loss: 11.4151\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.9639\n",
      "1/1 - 0s - loss: 11.3224\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.6649\n",
      "1/1 - 0s - loss: 11.2446\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 69.3197\n",
      "1/1 - 0s - loss: 11.1704\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 69.3767\n",
      "1/1 - 0s - loss: 11.0974\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 69.3077\n",
      "1/1 - 0s - loss: 11.0266\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 69.1180\n",
      "1/1 - 0s - loss: 10.9536\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.8380\n",
      "1/1 - 0s - loss: 10.8684\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.6214\n",
      "1/1 - 0s - loss: 10.8036\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.4945\n",
      "1/1 - 0s - loss: 10.7374\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.5011\n",
      "1/1 - 0s - loss: 10.5998\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.3431\n",
      "1/1 - 0s - loss: 10.5291\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.1040\n",
      "1/1 - 0s - loss: 10.4608\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.8935\n",
      "1/1 - 0s - loss: 10.4290\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 67.9092\n",
      "1/1 - 0s - loss: 10.3965\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.9287\n",
      "1/1 - 0s - loss: 10.3639\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.8662\n",
      "1/1 - 0s - loss: 10.3335\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.9357\n",
      "1/1 - 0s - loss: 10.2986\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.2469\n",
      "1/1 - 0s - loss: 10.2580\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.5984\n",
      "1/1 - 0s - loss: 10.2249\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.7859\n",
      "1/1 - 0s - loss: 10.1926\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.8828\n",
      "1/1 - 0s - loss: 10.1587\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 69.0070\n",
      "1/1 - 0s - loss: 10.1376\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.8067\n",
      "1/1 - 0s - loss: 10.1184\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.5743\n",
      "1/1 - 0s - loss: 10.1028\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.3676\n",
      "1/1 - 0s - loss: 10.0887\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.1941\n",
      "1/1 - 0s - loss: 10.0757\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 68.0422\n",
      "1/1 - 0s - loss: 10.0629\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.8938\n",
      "1/1 - 0s - loss: 10.0496\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.7470\n",
      "1/1 - 0s - loss: 10.0360\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.6071\n",
      "1/1 - 0s - loss: 10.0241\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.4864\n",
      "1/1 - 0s - loss: 10.0136\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.3706\n",
      "1/1 - 0s - loss: 10.0041\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.2518\n",
      "1/1 - 0s - loss: 9.9952\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 67.1298\n",
      "1/1 - 0s - loss: 9.9869\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.0134\n",
      "1/1 - 0s - loss: 9.9790\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 66.9160\n",
      "1/1 - 0s - loss: 9.9718\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 66.8429\n",
      "1/1 - 0s - loss: 9.9650\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.8015\n",
      "1/1 - 0s - loss: 9.9585\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.7997\n",
      "1/1 - 0s - loss: 9.9522\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 66.8389\n",
      "1/1 - 0s - loss: 9.9460\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 66.9113\n",
      "1/1 - 0s - loss: 9.9400\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.0043\n",
      "1/1 - 0s - loss: 9.9343\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.1086\n",
      "1/1 - 0s - loss: 9.9261\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.1876\n",
      "1/1 - 0s - loss: 9.9200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.2025\n",
      "1/1 - 0s - loss: 9.9133\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.1904\n",
      "1/1 - 0s - loss: 9.8947\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 67.1293\n",
      "1/1 - 0s - loss: 9.8906\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 67.0153\n",
      "1/1 - 0s - loss: 9.8878\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.8326\n",
      "1/1 - 0s - loss: 9.8854\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 66.5179\n",
      "1/1 - 0s - loss: 9.8786\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 66.2508\n",
      "1/1 - 0s - loss: 9.8764\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 66.0526\n",
      "1/1 - 0s - loss: 9.8745\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 65.7673\n",
      "1/1 - 0s - loss: 9.8726\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 65.5051\n",
      "1/1 - 0s - loss: 9.8709\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 65.4012\n",
      "1/1 - 0s - loss: 9.8693\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.3850\n",
      "1/1 - 0s - loss: 9.8679\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.4432\n",
      "1/1 - 0s - loss: 9.8666\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.5204\n",
      "1/1 - 0s - loss: 9.8655\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 65.5205\n",
      "1/1 - 0s - loss: 9.8645\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.4443\n",
      "1/1 - 0s - loss: 9.8636\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 65.2996\n",
      "1/1 - 0s - loss: 9.8628\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 65.1161\n",
      "1/1 - 0s - loss: 9.8620\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.9369\n",
      "1/1 - 0s - loss: 9.8612\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 64.7810\n",
      "1/1 - 0s - loss: 9.8604\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.6497\n",
      "1/1 - 0s - loss: 9.8597\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.5464\n",
      "1/1 - 0s - loss: 9.8590\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.4844\n",
      "1/1 - 0s - loss: 9.8584\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.4482\n",
      "1/1 - 0s - loss: 9.8578\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.3770\n",
      "1/1 - 0s - loss: 9.8573\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 64.2741\n",
      "1/1 - 0s - loss: 9.8568\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 64.1517\n",
      "1/1 - 0s - loss: 9.8564\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 64.0191\n",
      "1/1 - 0s - loss: 9.8560\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.9044\n",
      "1/1 - 0s - loss: 9.8556\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.8288\n",
      "1/1 - 0s - loss: 9.8552\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.7835\n",
      "1/1 - 0s - loss: 9.8549\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.7488\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.7488\n",
      "[4.114242861539711, 4.182009613420117, 7.984286134229045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_14:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_13:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_17:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_16:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_20:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_19:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_23:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Reshape_22:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_29/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_11:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_10:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_13:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_12:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_15:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_14:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_17:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_16:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_conv_29/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_14:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_13:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_17:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_16:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_20:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_19:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_23:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Reshape_22:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_7/graph_pool_28/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 4s - loss: 113.3999\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 80.1448\n",
      "1/1 - 0s - loss: 76.4651\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 105.8839\n",
      "1/1 - 0s - loss: 70.9690\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 115.1423\n",
      "1/1 - 0s - loss: 69.4765\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 108.6381\n",
      "1/1 - 0s - loss: 63.1244\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 94.9195\n",
      "1/1 - 0s - loss: 57.2399\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 80.1987\n",
      "1/1 - 0s - loss: 53.9871\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 68.3946\n",
      "1/1 - 0s - loss: 53.1933\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 59.9375\n",
      "1/1 - 0s - loss: 52.3782\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 55.1668\n",
      "1/1 - 0s - loss: 49.4267\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 53.8260\n",
      "1/1 - 0s - loss: 45.0670\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 55.2542\n",
      "1/1 - 0s - loss: 40.8021\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 58.9375\n",
      "1/1 - 0s - loss: 38.0108\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.4799\n",
      "1/1 - 0s - loss: 37.0961\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 67.1992\n",
      "1/1 - 0s - loss: 37.4320\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 68.5142\n",
      "1/1 - 0s - loss: 37.5508\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 66.7583\n",
      "1/1 - 0s - loss: 36.8813\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 62.5729\n",
      "1/1 - 0s - loss: 35.3999\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 57.1983\n",
      "1/1 - 0s - loss: 33.6064\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 51.9152\n",
      "1/1 - 0s - loss: 32.2266\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 47.7101\n",
      "1/1 - 0s - loss: 31.6443\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 45.1225\n",
      "1/1 - 0s - loss: 31.5410\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 44.2100\n",
      "1/1 - 0s - loss: 31.4847\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 44.8022\n",
      "1/1 - 0s - loss: 31.3327\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.5710\n",
      "1/1 - 0s - loss: 31.0672\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 48.9524\n",
      "1/1 - 0s - loss: 30.9138\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 51.0386\n",
      "1/1 - 0s - loss: 30.8768\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 52.2574\n",
      "1/1 - 0s - loss: 30.7730\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 52.2942\n",
      "1/1 - 0s - loss: 30.5620\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 51.1992\n",
      "1/1 - 0s - loss: 30.2174\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.2982\n",
      "1/1 - 0s - loss: 29.9573\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.1586\n",
      "1/1 - 0s - loss: 29.8558\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 45.3916\n",
      "1/1 - 0s - loss: 29.9610\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 44.2989\n",
      "1/1 - 0s - loss: 30.0940\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 43.9140\n",
      "1/1 - 0s - loss: 30.0847\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 44.1849\n",
      "1/1 - 0s - loss: 29.8997\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 45.0283\n",
      "1/1 - 0s - loss: 29.5601\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 46.2014\n",
      "1/1 - 0s - loss: 29.2733\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 47.3106\n",
      "1/1 - 0s - loss: 29.0955\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 48.0116\n",
      "1/1 - 0s - loss: 29.0327\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.2038\n",
      "1/1 - 0s - loss: 28.9641\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.8610\n",
      "1/1 - 0s - loss: 28.8564\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.0902\n",
      "1/1 - 0s - loss: 28.7056\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 46.2046\n",
      "1/1 - 0s - loss: 28.5890\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 45.5184\n",
      "1/1 - 0s - loss: 28.4535\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 45.2200\n",
      "1/1 - 0s - loss: 28.2847\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 45.3201\n",
      "1/1 - 0s - loss: 28.1333\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 45.7042\n",
      "1/1 - 0s - loss: 27.9603\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 46.4023\n",
      "1/1 - 0s - loss: 27.8623\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 47.2475\n",
      "1/1 - 0s - loss: 27.7908\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.8570\n",
      "1/1 - 0s - loss: 27.6985\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.0534\n",
      "1/1 - 0s - loss: 27.5866\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.7436\n",
      "1/1 - 0s - loss: 27.4513\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.1989\n",
      "1/1 - 0s - loss: 27.2842\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.6361\n",
      "1/1 - 0s - loss: 27.2134\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 46.0521\n",
      "1/1 - 0s - loss: 27.1042\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 45.9479\n",
      "1/1 - 0s - loss: 27.1386\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 46.0241\n",
      "1/1 - 0s - loss: 27.0784\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.2303\n",
      "1/1 - 0s - loss: 27.0389\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.5612\n",
      "1/1 - 0s - loss: 26.9421\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.8875\n",
      "1/1 - 0s - loss: 26.8120\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.2248\n",
      "1/1 - 0s - loss: 26.7174\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.5152\n",
      "1/1 - 0s - loss: 26.6310\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.6473\n",
      "1/1 - 0s - loss: 26.5715\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.5582\n",
      "1/1 - 0s - loss: 26.4773\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.1929\n",
      "1/1 - 0s - loss: 26.4112\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 46.8655\n",
      "1/1 - 0s - loss: 26.3334\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.6493\n",
      "1/1 - 0s - loss: 26.2359\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 46.5128\n",
      "1/1 - 0s - loss: 26.1642\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 46.5638\n",
      "1/1 - 0s - loss: 26.1206\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 46.7937\n",
      "1/1 - 0s - loss: 26.0173\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 47.1140\n",
      "1/1 - 0s - loss: 25.9686\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.4883\n",
      "1/1 - 0s - loss: 25.8590\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 47.6859\n",
      "1/1 - 0s - loss: 25.8043\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.7131\n",
      "1/1 - 0s - loss: 25.7417\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 47.5336\n",
      "1/1 - 0s - loss: 25.6438\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.3847\n",
      "1/1 - 0s - loss: 25.5680\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.3555\n",
      "1/1 - 0s - loss: 25.4983\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 47.5290\n",
      "1/1 - 0s - loss: 25.4270\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.8062\n",
      "1/1 - 0s - loss: 25.3656\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.9691\n",
      "1/1 - 0s - loss: 25.2979\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.0688\n",
      "1/1 - 0s - loss: 25.2324\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.1565\n",
      "1/1 - 0s - loss: 25.1943\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.1443\n",
      "1/1 - 0s - loss: 25.1146\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 48.0068\n",
      "1/1 - 0s - loss: 25.0684\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.8419\n",
      "1/1 - 0s - loss: 24.9861\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.7909\n",
      "1/1 - 0s - loss: 24.9412\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.8719\n",
      "1/1 - 0s - loss: 24.8709\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 48.0999\n",
      "1/1 - 0s - loss: 24.7908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 48.4025\n",
      "1/1 - 0s - loss: 24.7754\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 48.6081\n",
      "1/1 - 0s - loss: 24.7106\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 48.6930\n",
      "1/1 - 0s - loss: 24.6459\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 48.6261\n",
      "1/1 - 0s - loss: 24.5958\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 48.4659\n",
      "1/1 - 0s - loss: 24.5503\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 48.3104\n",
      "1/1 - 0s - loss: 24.4670\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.2275\n",
      "1/1 - 0s - loss: 24.4144\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 48.2252\n",
      "1/1 - 0s - loss: 24.3782\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 48.3234\n",
      "1/1 - 0s - loss: 24.3279\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.4021\n",
      "1/1 - 0s - loss: 24.2521\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.4177\n",
      "1/1 - 0s - loss: 24.1970\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.3475\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.3475\n",
      "[5.9718297233042925, 5.306703883732268, 5.300665385386257, 6.953237468367084]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_14:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_13:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_17:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_16:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_20:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_19:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_23:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Reshape_22:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_11:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_10:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_13:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_12:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_15:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_14:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_17:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_16:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_conv_31/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_14:0\", shape=(1128,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_13:0\", shape=(1128, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_17:0\", shape=(3778,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_16:0\", shape=(3778, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_20:0\", shape=(7452,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_19:0\", shape=(7452, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_23:0\", shape=(44,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Reshape_22:0\", shape=(44, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_7/graph_pool_30/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 5s - loss: 32.2594\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 22.0933\n",
      "1/1 - 0s - loss: 26.2027\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 21.7813\n",
      "1/1 - 0s - loss: 23.6976\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 20.6649\n",
      "1/1 - 0s - loss: 22.2627\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.5302\n",
      "1/1 - 0s - loss: 21.1463\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.6347\n",
      "1/1 - 0s - loss: 19.8444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.4768\n",
      "1/1 - 0s - loss: 18.3189\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.4084\n",
      "1/1 - 0s - loss: 17.6662\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.1175\n",
      "1/1 - 0s - loss: 17.1518\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.6333\n",
      "1/1 - 0s - loss: 16.5096\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.3211\n",
      "1/1 - 0s - loss: 16.0574\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.0966\n",
      "1/1 - 0s - loss: 15.6610\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.0263\n",
      "1/1 - 0s - loss: 15.2565\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.9046\n",
      "1/1 - 0s - loss: 14.8192\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.8945\n",
      "1/1 - 0s - loss: 14.4240\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.8430\n",
      "1/1 - 0s - loss: 14.0903\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.7500\n",
      "1/1 - 0s - loss: 13.8503\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.7165\n",
      "1/1 - 0s - loss: 13.6866\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.5213\n",
      "1/1 - 0s - loss: 13.5245\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.2747\n",
      "1/1 - 0s - loss: 13.3898\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.1555\n",
      "1/1 - 0s - loss: 13.2486\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.1823\n",
      "1/1 - 0s - loss: 13.1205\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.1639\n",
      "1/1 - 0s - loss: 13.0639\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.0224\n",
      "1/1 - 0s - loss: 12.9999\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.0228\n",
      "1/1 - 0s - loss: 12.9389\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.2207\n",
      "1/1 - 0s - loss: 12.8987\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.2967\n",
      "1/1 - 0s - loss: 12.8620\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.3499\n",
      "1/1 - 0s - loss: 12.8212\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.3550\n",
      "1/1 - 0s - loss: 12.7839\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.3683\n",
      "1/1 - 0s - loss: 12.7552\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.4574\n",
      "1/1 - 0s - loss: 12.7300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.5431\n",
      "1/1 - 0s - loss: 12.7045\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.6054\n",
      "1/1 - 0s - loss: 12.6772\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.6221\n",
      "1/1 - 0s - loss: 12.6572\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.5790\n",
      "1/1 - 0s - loss: 12.6462\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.5423\n",
      "1/1 - 0s - loss: 12.6383\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.6200\n",
      "1/1 - 0s - loss: 12.6319\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.7587\n",
      "1/1 - 0s - loss: 12.6269\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.8588\n",
      "1/1 - 0s - loss: 12.6229\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.8406\n",
      "1/1 - 0s - loss: 12.6193\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.6956\n",
      "1/1 - 0s - loss: 12.6165\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 16.4900\n",
      "1/1 - 0s - loss: 12.6150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.2706\n",
      "1/1 - 0s - loss: 12.6146\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 16.0715\n",
      "1/1 - 0s - loss: 12.6147\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.8992\n",
      "1/1 - 0s - loss: 12.6145\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.7649\n",
      "1/1 - 0s - loss: 12.6145\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 15.6761\n",
      "1/1 - 0s - loss: 12.6143\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.6544\n",
      "1/1 - 0s - loss: 12.6140\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.6752\n",
      "1/1 - 0s - loss: 12.6136\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 15.6878\n",
      "1/1 - 0s - loss: 12.6133\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.7071\n",
      "1/1 - 0s - loss: 12.6131\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.7559\n",
      "1/1 - 0s - loss: 12.6129\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.8315\n",
      "1/1 - 0s - loss: 12.6123\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.9101\n",
      "1/1 - 0s - loss: 12.6114\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 15.9940\n",
      "1/1 - 0s - loss: 12.6105\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.0878\n",
      "1/1 - 0s - loss: 12.6099\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.1669\n",
      "1/1 - 0s - loss: 12.6093\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.2036\n",
      "1/1 - 0s - loss: 12.6087\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.2081\n",
      "1/1 - 0s - loss: 12.6080\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1770\n",
      "1/1 - 0s - loss: 12.6075\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1101\n",
      "1/1 - 0s - loss: 12.6071\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.0534\n",
      "1/1 - 0s - loss: 12.6067\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.9765\n",
      "1/1 - 0s - loss: 12.6062\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.8719\n",
      "1/1 - 0s - loss: 12.6058\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.7675\n",
      "1/1 - 0s - loss: 12.6055\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.6740\n",
      "1/1 - 0s - loss: 12.6052\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.6096\n",
      "1/1 - 0s - loss: 12.6050\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.5543\n",
      "1/1 - 0s - loss: 12.6048\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.5076\n",
      "1/1 - 0s - loss: 12.6048\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.4791\n",
      "1/1 - 0s - loss: 12.6046\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.4924\n",
      "1/1 - 0s - loss: 12.6045\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.5453\n",
      "1/1 - 0s - loss: 12.6044\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.6120\n",
      "1/1 - 0s - loss: 12.6043\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.6659\n",
      "1/1 - 0s - loss: 12.6041\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.6975\n",
      "1/1 - 0s - loss: 12.6038\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.7048\n",
      "1/1 - 0s - loss: 12.6036\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.6793\n",
      "1/1 - 0s - loss: 12.6033\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.6019\n",
      "1/1 - 0s - loss: 12.6030\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.4875\n",
      "1/1 - 0s - loss: 12.6027\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.3686\n",
      "1/1 - 0s - loss: 12.6025\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.2929\n",
      "1/1 - 0s - loss: 12.6023\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.2543\n",
      "1/1 - 0s - loss: 12.6021\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.2263\n",
      "1/1 - 0s - loss: 12.6020\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.1973\n",
      "1/1 - 0s - loss: 12.6019\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.1656\n",
      "1/1 - 0s - loss: 12.6018\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.1317\n",
      "1/1 - 0s - loss: 12.6017\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.0990\n",
      "1/1 - 0s - loss: 12.6016\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.0806\n",
      "1/1 - 0s - loss: 12.6014\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.0589\n",
      "1/1 - 0s - loss: 12.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 15.0380\n",
      "1/1 - 0s - loss: 12.6012\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.0191\n",
      "1/1 - 0s - loss: 12.6010\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.9953\n",
      "1/1 - 0s - loss: 12.6009\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.9711\n",
      "1/1 - 0s - loss: 12.6008\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.9560\n",
      "1/1 - 0s - loss: 12.6006\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.9488\n",
      "1/1 - 0s - loss: 12.6006\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.9418\n",
      "1/1 - 0s - loss: 12.6005\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 14.9325\n",
      "1/1 - 0s - loss: 12.6004\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 14.9086\n",
      "1/1 - 0s - loss: 12.6004\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.8915\n",
      "1/1 - 0s - loss: 12.6003\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.8951\n",
      "1/1 - 0s - loss: 12.6002\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.8961\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.8961\n",
      "[4.114242861539711, 4.182009613420117, 7.984286134229045, 3.859549823461632]\n"
     ]
    }
   ],
   "source": [
    "k_fold = k\n",
    "\n",
    "# PGNN model variables\n",
    "pgnn_train_losses = [[] for _ in range(k_fold)]\n",
    "pgnn_val_losses = [[] for _ in range(k_fold)]\n",
    "pgnn_rmse_train, pgnn_rmse_test = [], []\n",
    "\n",
    "# Data Driven model variables\n",
    "dd_train_losses = [[] for _ in range(k_fold)]\n",
    "dd_val_losses = [[] for _ in range(k_fold)]\n",
    "dd_rmse_train, dd_rmse_test, rmse_gbnsr6_ex, rmse_gb_pb = [], [], [], []\n",
    "\n",
    "# Physics-based model variables\n",
    "physics_based_rmse_train, physics_based_rmse_test, rmse_pbsa_ex , rmse_gbnsr6_ex = [], [], [], []\n",
    "gb_r_squared, pb_r_squared, pbgb_r_squared = [], [], []\n",
    "\n",
    "for fold in range(k_fold):\n",
    "    # fold=0 -> 0 * (0.25 * 72) = 0\n",
    "    # fold=1 -> 1 * (0.25 * 72) = 18\n",
    "    # fold=2 -> 2 * (0.25 * 72) = 36\n",
    "    # fold=3 -> 3 * (0.25 *72) = 54\n",
    "    X, X_ids, host_names_val,guest_names_val, host_names_test, guest_names_test = [], [], [], [], [], []\n",
    "    host_names_train, guest_names_train, X_val_featurized, X_test_featurized, X_train_featurized  = [], [], [], [], []\n",
    "    \n",
    "    \n",
    "    for k in PDBs.keys():\n",
    "        X_ids.append(k)\n",
    "        X.append(featurizer.featurize(PDBs[k]))\n",
    "    val_split_index_begin = int(fold * TEST_SIZE)\n",
    "#     print(f\"begin {val_split_index_begin}\")\n",
    "    val_split_index_end = int(val_split_index_begin) + int(TEST_SIZE)\n",
    "#     print(f\"end {val_split_index_end}\")\n",
    "    # validation\n",
    "    host_names_val = host_names[val_split_index_begin:val_split_index_end]\n",
    "    guest_names_val = guest_names[val_split_index_begin:val_split_index_end]\n",
    "    # Test set\n",
    "    host_names_test = host_names[val_split_index_begin:val_split_index_end]\n",
    "    guest_names_test = guest_names[val_split_index_begin:val_split_index_end]\n",
    "    # Train set\n",
    "    host_names_train = [host_names[i] for i in range(len(host_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "    guest_names_train = [guest_names[i] for i in range(len(guest_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "\n",
    "    X = [x[0] for x in X]\n",
    "    \n",
    "    X_val_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_test_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "#     for i in range(val_split_index_begin,val_split_index_end):\n",
    "#         X = X.pop(i)\n",
    "    X_train_featurized = [X[i] for i in range(len(X)) if i not in range(val_split_index_begin, val_split_index_end)]\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    x_add_train, x_add_val, x_add_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    # Train\n",
    "    for i in range(len(host_names_train)):\n",
    "        new_df = df[(df['Host'] == host_names_train[i]) & (df['Guest'] == guest_names_train[i])]\n",
    "        y_train.append(new_df['EX _H_(kcal/mol)'].to_numpy()[0])\n",
    "        x_add_train.append(new_df[[c for c in df.columns if ('Etot' not in c) and ('delta' not in c)\n",
    "                             and ('Ex_difference' not in c) and ('gb_' in c or 'VDWAALS' in c)]].to_numpy()[0])\n",
    "    y_train = np.array(y_train)\n",
    "    # Val\n",
    "    for i in range(len(host_names_val)):\n",
    "        new_df = df[(df['Host'] == host_names_val[i]) & (df['Guest'] == guest_names_val[i])]\n",
    "        y_val.append(new_df['EX _H_(kcal/mol)'].to_numpy()[0])\n",
    "        x_add_val.append(new_df[[c for c in df.columns if ('Etot' not in c) and ('delta' not in c)\n",
    "                             and ('Ex_difference' not in c) and ('gb_' in c or 'VDWAALS' in c)]].to_numpy()[0])\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Test\n",
    "    for i in range(len(host_names_test)):\n",
    "        new_df = df[(df['Host'] == host_names_test[i]) & (df['Guest'] == guest_names_test[i])]\n",
    "        y_test.append(new_df['EX _H_(kcal/mol)'].to_numpy()[0])\n",
    "        x_add_test.append(new_df[[c for c in df.columns if ('Etot' not in c) and ('delta' not in c)\n",
    "                             and ('Ex_difference' not in c) and ('gb_' in c or 'VDWAALS' in c)]].to_numpy()[0])\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_preprocessed_train, x_preprocessed_val, x_preprocessed_test = [], [], []\n",
    "    \n",
    "    ## Step\n",
    "    \n",
    "    # for X train\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "    x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "    ## for X val\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "    x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "\n",
    "    ## for X test\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "    x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_test.append(np.array(x_add_test))\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    # Train\n",
    "    x_train = np.full([14, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_train):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "    # Validation\n",
    "    x_val = np.full([14, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_val):\n",
    "        if len(j.shape) > 1:\n",
    "            x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "    # Test\n",
    "    x_test = np.full([14, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_test):\n",
    "        if len(j.shape) > 1:\n",
    "            x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_test = x_test.reshape([1] + list(x_test.shape))\n",
    "    \n",
    "    # Variable initializations for models\n",
    "    \n",
    "    val_size = len(y_val)\n",
    "    train_size = len(y_train)\n",
    "    \n",
    "    # PGNN Model\n",
    "    batch_size = len(host_names_train)\n",
    "    hybrid_model = PGNN(len(y_train))\n",
    "    hybrid_model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        hybrid_model.modify_graphgather(train_size)\n",
    "        hybrid_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        loss = hybrid_model.fit(x_train, y_train.reshape([1, -1]), epochs=1, verbose=2)\n",
    "        pgnn_train_losses[fold].append(loss.history['loss'][0])\n",
    "        hybrid_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        hybrid_model.modify_graphgather(val_size)\n",
    "        pgnn_val_losses[fold].append(hybrid_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "        \n",
    "    hybrid_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    hybrid_model.modify_graphgather(len(y_test))\n",
    "    evalu = hybrid_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # PGNN Testing RMSE calculation\n",
    "    pgnn_rmse_test.append(np.sqrt(evalu))\n",
    "    print(pgnn_rmse_test)\n",
    "    # PGNN Training RMSE calculation\n",
    "    train_loss = pgnn_train_losses[fold][-1]\n",
    "    pgnn_rmse_train.append(math.sqrt(train_loss))\n",
    "    \n",
    "    # Data Driven model\n",
    "    dd_model = GBGraphConvModel(len(y_train))\n",
    "    dd_model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        dd_model.modify_graphgather(train_size)\n",
    "        dd_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        loss = dd_model.fit(x_train, y_train.reshape([1, -1]), epochs=1, verbose=2)\n",
    "        dd_train_losses[fold].append(loss.history['loss'][0])\n",
    "        dd_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        dd_model.modify_graphgather(val_size)\n",
    "        dd_val_losses[fold].append(dd_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "    \n",
    "    dd_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    dd_model.modify_graphgather(len(y_test))\n",
    "    dd_evaluate = dd_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # Data Driven Testing RMSE calculation\n",
    "    dd_rmse_test.append(np.sqrt(dd_evaluate))\n",
    "    print(dd_rmse_test)\n",
    "    # Data Driven training RMSE calculation\n",
    "    dd_train_loss = dd_train_losses[fold][-1]\n",
    "    dd_rmse_train.append(math.sqrt(dd_train_loss))\n",
    "    \n",
    "    # Physics-based model\n",
    "    train_sum=0\n",
    "    for i in range(len(host_names_train)):\n",
    "        new_df = df[(df['Host'] == host_names_train[i]) & (df['Guest'] == guest_names_train[i])]\n",
    "        train_sum += new_df['gb_Ex_difference'].to_numpy()[0] **2\n",
    "\n",
    "\n",
    "    test_sum = 0\n",
    "    for i in range(len(host_names_test)):\n",
    "        new_df = df[(df['Host'] == host_names_test[i]) & (df['Guest'] == guest_names_test[i])]\n",
    "        test_sum += new_df['gb_Ex_difference'].to_numpy()[0] **2\n",
    "        \n",
    "    physics_based_rmse_train.append(math.sqrt(train_sum / len(host_names_train)))\n",
    "    physics_based_rmse_test.append(math.sqrt((test_sum) / len(host_names_test)))\n",
    "    \n",
    "    # RMSE gbnsr6 vs experimental\n",
    "    mse_gb_ex = mean_squared_error(df['EX _delta_H_(kcal/mol)'], df['gb_delta_H'])\n",
    "    rmse_gbnsr6_ex.append(math.sqrt(mse_gb_ex))\n",
    "    \n",
    "    # RMSE pbsa vs experimental\n",
    "    mse_pb_ex = mean_squared_error(df['EX _delta_H_(kcal/mol)'], df['pb_delta_H'])\n",
    "    rmse_pbsa_ex.append(math.sqrt(mse_pb_ex))\n",
    "\n",
    "    # RMSE gbnsr6 vs pbsa\n",
    "    mse_gb_pb = mean_squared_error(df['pb_delta_H'], df['gb_delta_H'])\n",
    "    rmse_gb_pb.append(math.sqrt(mse_gb_pb))\n",
    "    \n",
    "    # GBNSR6 R^2 \n",
    "    gb_correlation_matrix = np.corrcoef(df['gb_delta_H'], df['EX _H_(kcal/mol)'])\n",
    "    gb_correlation_gbex = gb_correlation_matrix[0,1]\n",
    "    gb_r_squared.append(gb_correlation_gbex**2)\n",
    "    \n",
    "    # PBSA R^2\n",
    "    pb_correlation_matrix = np.corrcoef(df['pb_delta_H'], df['EX _H_(kcal/mol)'])\n",
    "    pb_correlation_pbex = pb_correlation_matrix[0,1]\n",
    "    pb_r_squared.append(pb_correlation_pbex**2)\n",
    "    \n",
    "    # PBSA - GBNSR6 R^2\n",
    "    pbgb_correlation_matrix = np.corrcoef(df['gb_delta_H'], df['pb_delta_H'])\n",
    "    pbgb_correlation = pbgb_correlation_matrix[0,1]\n",
    "    pbgb_r_squared.append(pbgb_correlation**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.689773716398127, 9.235036600751629, 9.774143826272798, 7.598269923914699]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_based_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.116540038105953, 9.116540038105953, 9.116540038105953, 9.116540038105953]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_gbnsr6_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.114242861539711, 4.182009613420117, 7.984286134229045, 3.859549823461632]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.9718297233042925, 5.306703883732268, 5.300665385386257, 6.953237468367084]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgnn_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.917277132820226, 9.076697417899922, 8.886531410490239, 9.569247675564485]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_based_rmse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model Comparisons </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Training set\n",
    "average_dd_rmse_train = sum(dd_rmse_train) / len(dd_rmse_train)\n",
    "average_pgnn_rmse_train = sum(pgnn_rmse_train) / len(pgnn_rmse_train)\n",
    "average_physics_based_rmse_train = sum(physics_based_rmse_train) / len(physics_based_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|        Train Set RMSE       |\n",
      "+--------+-------------+------+\n",
      "| GBNSR6 | Data Driven | PGNN |\n",
      "+--------+-------------+------+\n",
      "|  9.11  |     3.43    | 5.11 |\n",
      "+--------+-------------+------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "# Train\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Train Set RMSE\"\n",
    "rmse_table.field_names = [\"GBNSR6\", \"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(average_physics_based_rmse_train), \"{:.2f}\".format(average_dd_rmse_train),\"{:.2f}\".format(average_pgnn_rmse_train)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Testing set\n",
    "average_dd_rmse_test = sum(dd_rmse_test) / len(dd_rmse_test)\n",
    "average_pgnn_rmse_test = sum(pgnn_rmse_test) / len(pgnn_rmse_test)\n",
    "average_physics_based_rmse_test = sum(physics_based_rmse_test) / len(physics_based_rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.689773716398127, 9.235036600751629, 9.774143826272798, 7.598269923914699]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_based_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|        Test Set RMSE        |\n",
      "+--------+-------------+------+\n",
      "| GBNSR6 | Data Driven | PGNN |\n",
      "+--------+-------------+------+\n",
      "|  9.07  |     5.04    | 5.88 |\n",
      "+--------+-------------+------+\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Test Set RMSE\"\n",
    "rmse_table.field_names = [\"GBNSR6\", \"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(average_physics_based_rmse_test), \"{:.2f}\".format(average_dd_rmse_test),\"{:.2f}\".format(average_pgnn_rmse_test)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Driven Model performance evaluation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_dd_train_losses = [sum(x)/len(x) for x in zip(*dd_train_losses)]\n",
    "average_dd_val_losses = [sum(x)/len(x) for x in zip(*dd_val_losses)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Loss per Epoch graph on average of the K-fold cross validations </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "average_dd_train_losses = [sum(x)/len(x) for x in zip(*dd_train_losses)]\n",
    "average_dd_val_losses = [sum(x)/len(x) for x in zip(*dd_val_losses)]\n",
    "# f, ax = plt.subplots()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_dd_train_losses)), average_dd_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_dd_val_losses)), average_dd_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "plt.ylim(0,100)\n",
    "plt.savefig('ind_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PGNN Model performance evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pgnn_train_losses = [sum(x)/len(x) for x in zip(*pgnn_train_losses)]\n",
    "average_pgnn_val_losses = [sum(x)/len(x) for x in zip(*pgnn_val_losses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# f, ax = plt.subplots()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_pgnn_train_losses)), average_pgnn_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_pgnn_val_losses)), average_pgnn_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "plt.ylim(0,100)\n",
    "plt.savefig('comb_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model variance Box Plot </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_dict = {\n",
    "    \"pgnn_train\" : [x for x in pgnn_rmse_train],\n",
    "    \"dd_train\" : [x for x in dd_rmse_train],\n",
    "    \"pgnn_validation\" : [x for x in pgnn_rmse_test],\n",
    "    \"dd_validation\" : [x for x in dd_rmse_test]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.347233757678163, 5.380933635773864, 4.806191607493852, 4.919045643240485]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgnn_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.917277132820226, 9.076697417899922, 8.886531410490239, 9.569247675564485]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_based_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance\n",
    "import statistics\n",
    "train_results_dict_variance = {\n",
    "    \"pgnn_train_variance\" : [statistics.stdev(pgnn_rmse_train)],\n",
    "    \"dd_train_variance\" : [statistics.stdev(dd_rmse_train)],\n",
    "    \"pgnn_validation_variance\" : [statistics.stdev(pgnn_rmse_test)],\n",
    "    \"dd_validation_variance\" : [statistics.stdev(dd_rmse_test)],\n",
    "    \"dd_rmse_test_variance\" : [statistics.stdev(dd_rmse_test)],\n",
    "    \"PGNN_rmse_test_variance\" : [statistics.stdev(pgnn_rmse_test)],\n",
    "    \"physics_rmse_test_variance\" : [statistics.stdev(physics_based_rmse_test)],\n",
    "    \"physics_based_train_variance\" : [statistics.stdev(physics_based_rmse_train)],\n",
    "}\n",
    "import statistics\n",
    "train_results_dict_mean = {\n",
    "    \"pgnn_train_mean\" : [statistics.mean(pgnn_rmse_train)],\n",
    "    \"dd_train_mean\" : [statistics.mean(dd_rmse_train)],\n",
    "    \"pgnn_validation_mean\" : [statistics.mean(pgnn_rmse_test)],\n",
    "    \"dd_validation_mean\" : [statistics.mean(dd_rmse_test)],\n",
    "    \"dd_rmse_test_mean\" : [statistics.mean(dd_rmse_test)],\n",
    "    \"PGNN_rmse_test_mean\" : [statistics.mean(pgnn_rmse_test)],\n",
    "    \"physics_rmse_test_mean\" : [statistics.mean(physics_based_rmse_test)],\n",
    "    \"physics_based_train_mean\" : [statistics.mean(physics_based_rmse_train)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.347233757678163, 5.380933635773864, 4.806191607493852, 4.919045643240485]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgnn_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pgnn_train': [5.347233757678163,\n",
       "  5.380933635773864,\n",
       "  4.806191607493852,\n",
       "  4.919045643240485],\n",
       " 'dd_train': [3.446420504365031,\n",
       "  3.59492141871194,\n",
       "  3.139248674491304,\n",
       "  3.549681641178987],\n",
       " 'pgnn_validation': [5.9718297233042925,\n",
       "  5.306703883732268,\n",
       "  5.300665385386257,\n",
       "  6.953237468367084],\n",
       " 'dd_validation': [4.114242861539711,\n",
       "  4.182009613420117,\n",
       "  7.984286134229045,\n",
       "  3.859549823461632]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pgnn_train_variance': [0.29348655584024935],\n",
       " 'dd_train_variance': [0.20518475910887432],\n",
       " 'pgnn_validation_variance': [0.7798567662969069],\n",
       " 'dd_validation_variance': [1.9710706164204246],\n",
       " 'dd_rmse_test_variance': [1.9710706164204246],\n",
       " 'PGNN_rmse_test_variance': [0.7798567662969069],\n",
       " 'physics_rmse_test_variance': [1.012108412660395],\n",
       " 'physics_based_train_variance': [0.3157393546159056]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results_dict_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pgnn_train_mean': [5.113351161046591],\n",
       " 'dd_train_mean': [3.4325680596868153],\n",
       " 'pgnn_validation_mean': [5.883109115197476],\n",
       " 'dd_validation_mean': [5.035022108162626],\n",
       " 'dd_rmse_test_mean': [5.035022108162626],\n",
       " 'PGNN_rmse_test_mean': [5.883109115197476],\n",
       " 'physics_rmse_test_mean': [9.074306016834313],\n",
       " 'physics_based_train_mean': [9.112438409193718]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results_dict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Train box plot\n",
    "plt.figure(figsize=(10,5))\n",
    "# plt.title(\"Train & Test RMSE varianc\")\n",
    "box = plt.boxplot([x for x in train_results_dict.values()],labels=[x for x in train_results_dict.keys()],\n",
    "                  patch_artist=True, showfliers=False)\n",
    "# plt.xlabel(\"PGNN and DD train\")\n",
    "plt.ylabel(\"RMSE (kcal/mol)\")\n",
    "# plt.xlim(3.2,  7)\n",
    "plt.rc('font', size=15)\n",
    "\n",
    "colors = ['lightblue', 'lightgreen', 'pink']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_dict = {\n",
    "    \"pgnn_train\" : [x for x in pgnn_rmse_train],\n",
    "    \"dd_train\" : [x for x in dd_rmse_train]\n",
    "#     \"gbnsr6_train\" : [x for x in physics_based_rmse_train]\n",
    "}\n",
    "test_results_dict ={\n",
    "    \"pgnn_test\" : [x for x in pgnn_rmse_test],\n",
    "    \"dd_test\" : [x for x in dd_rmse_test]\n",
    "#     \"gbnsr6_train\" : [x for x in physics_based_rmse_test]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 7.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train box plot\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.title(\"Train RMSE comparison\")\n",
    "plt.boxplot([x for x in train_results_dict.values()],labels=[x for x in train_results_dict.keys()],\n",
    "            vert=False, patch_artist=True)\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"PGNN and Data Driven train\")\n",
    "plt.xlim(3,7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 7.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test box plot\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.title(\"Test RMSE comparison\")\n",
    "box = plt.boxplot([x for x in test_results_dict.values()],labels=[x for x in test_results_dict.keys()],\n",
    "                  vert=False, patch_artist=True)\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"PGNN and Data Driven test\")\n",
    "\n",
    "plt.xlim(3, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gb_graph_conv_model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "graph_conv_30 (GraphConv)    multiple                  51072     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "graph_pool_30 (GraphPool)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "graph_conv_31 (GraphConv)    multiple                  22176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "graph_pool_31 (GraphPool)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             multiple                  2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "graph_gather_15 (GraphGather multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             multiple                  129       \n",
      "=================================================================\n",
      "Total params: 75,873\n",
      "Trainable params: 75,681\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pgnn_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "graph_conv_28 (GraphConv)    multiple                  51072     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "graph_pool_28 (GraphPool)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "graph_conv_29 (GraphConv)    multiple                  22176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "graph_pool_29 (GraphPool)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             multiple                  2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "graph_gather_14 (GraphGather multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  129       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 75,890\n",
      "Trainable params: 75,698\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-deepchem-jupyter",
   "language": "python",
   "name": "rdkit-deepchem-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
